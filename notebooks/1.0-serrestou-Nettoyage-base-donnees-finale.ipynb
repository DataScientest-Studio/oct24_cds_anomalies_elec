{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de cette partie est de faire une inpsection des données pour gérér les valeurs manquantes dans la bases construites avec les donnnées consommation + données météo + données rayonnement solaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import gzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Une classe pour supprimer des colonnes dans la proportion des valeurs NAN  > 50\n",
    "class ColumnDrop(BaseEstimator,TransformerMixin):\n",
    "    # BaseEstimator contient les méthodes get_params et set_params.\n",
    "    # TransformerMixin contient la méthode fit_transform.\n",
    "    def __init__(self, seuil_for_drop):\n",
    "        self.seuil_for_drop = seuil_for_drop\n",
    "    def fit(self, X, y=None):\n",
    "         # Ne fait rien\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # Supression des colonnes dont le pourcentage > seuil_for_drop \n",
    "        for col in X.columns:\n",
    "            if (100*X[col].isna().sum()/len(X) > self.seuil_for_drop):\n",
    "                X.drop(columns=[col], inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une classe pour supprimer des lignes qui contiennent des valeurs NAN  pour une colonne donnée\n",
    "\n",
    "class RowDrop(BaseEstimator,TransformerMixin):\n",
    "    # BaseEstimator contient les méthodes get_params et set_params.\n",
    "    # TransformerMixin contient la méthode fit_transform.\n",
    "    def __init__(self, col_for_drop):\n",
    "        # col_for_drop la colonne qu'on utilise pour supprimer les lignes contenant des nan\n",
    "        self.col_for_drop = col_for_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "         # Ne fait rien\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # # Supression des lignes dont la colonne Profil est nan\n",
    "        rowindex_to_drop = X.loc[X[self.col_for_drop].isna()].index\n",
    "        X.drop(index=rowindex_to_drop, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestionPas30Minutes(BaseEstimator,TransformerMixin):\n",
    "    # BaseEstimator contient les méthodes get_params et set_params.\n",
    "    # TransformerMixin contient la méthode fit_transform.\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self, X, y=None):\n",
    "         # Ne fait rien\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # Pour remplacer par la valeur la plus proche dans le temps, on ordonne par année, moi, jour et heure\n",
    "        X.sort_values(['Profil', 'Plage de puissance souscrite','year', 'month', 'day', 'h'], ascending=[True, True,True,True, True, True], inplace=True)\n",
    "        X['mn'] = X['mn'] + [0 if i % 2 == 0 else 30 for i in range(len(X))]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestionValeurManquante(BaseEstimator,TransformerMixin):\n",
    "    # BaseEstimator contient les méthodes get_params et set_params.\n",
    "    # TransformerMixin contient la méthode fit_transform.\n",
    "    def __init__(self, column_name,mask, methode =\"ffill\"):\n",
    "        self.column_name = column_name\n",
    "        self.methode = methode\n",
    "        self.mask = mask\n",
    "    def fit(self, X, y=None):\n",
    "         # Ne fait rien\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # Pour remplacer par la valeur la plus proche dans le temps, on ordonne par année, moi, jour et heure\n",
    "        X.sort_values(['Profil', 'Plage de puissance souscrite','year', 'month', 'day', 'h'], ascending=[True, True,True,True, True, True], inplace=True)\n",
    "        rolling_mean  = X.loc[self.mask, self.column_name].dropna().mean()\n",
    "        X.loc[self.mask, self.column_name] = X.loc[self.mask, self.column_name].fillna(rolling_mean)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin traitement Auvergne-Rhône-Alpes\n",
      "fin traitement Hauts-de-France\n",
      "fin traitement Provence-Alpes-Côte-d'Azur\n",
      "fin traitement Grand-Est\n",
      "fin traitement Occitanie\n",
      "fin traitement Normandie\n",
      "fin traitement Nouvelle-Aquitaine\n",
      "fin traitement Centre-Val-de-Loire\n",
      "fin traitement Bourgogne-Franche-Comté\n",
      "fin traitement Bretagne\n",
      "fin traitement Pays-de-la-Loire\n",
      "fin traitement Île-de-France\n"
     ]
    }
   ],
   "source": [
    "# lecture des csv contenant les bases de données conso+meteo-rayonnement\n",
    "\n",
    "\n",
    "folder_projet_BD = r\"D:\\MesDocuments\\Formation\\DataScientist_PSL\\Projet\\BD\"\n",
    "folder_BD_conso_meteo = os.path.join(folder_projet_BD, 'conso-inf36-meteo-rayonnement-region')\n",
    "\n",
    "filename = 'departements-region.csv'\n",
    "file = os.path.join(folder_projet_BD, filename)\n",
    "df_depa_region = pd.read_csv(file)\n",
    "df_depa_region['region_name'] = df_depa_region['region_name'].apply(lambda s : s.replace(\" \", '-'))\n",
    "Liste_region = df_depa_region['region_name'].unique().tolist()\n",
    "\n",
    "for elem in ['Guadeloupe', 'Martinique', 'Guyane','La-Réunion', 'Mayotte', 'Corse']:\n",
    "    Liste_region.remove(elem)\n",
    "\n",
    "template_start_in= 'conso-inf36-meteo-rayonnement-'\n",
    "template_end_in='-' + str(2023) + '-' + str(2024) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "folder_BD_meteo_rayonnement_out = os.path.join(folder_projet_BD, 'conso-inf36-meteo-rayonnement-region-propre')\n",
    "if not os.path.isdir(folder_BD_meteo_rayonnement_out):\n",
    "    os.mkdir(folder_BD_meteo_rayonnement_out)\n",
    "\n",
    "\n",
    "def nettoyage_BD(reg):\n",
    "    filename = f\"{template_start_in}{reg}{template_end_in}\" \n",
    "    file = os.path.join(folder_BD_conso_meteo, filename)\n",
    "    # lecture de la BD meteo de la région \n",
    "    df_fusion= pd.read_csv(file)\n",
    "\n",
    "\n",
    "    # Gestion des minutes pour avoir le pas 1/2 h\n",
    "    gestionminute = GestionPas30Minutes()\n",
    "    gestionminute.fit_transform(df_fusion)\n",
    "\n",
    "    # Nettoyage \n",
    "    # Suppresion des colonnes dont la proportion des nan dépasse 50%\n",
    "    columndrop = ColumnDrop(50)\n",
    "    columndrop.fit_transform(df_fusion)\n",
    "\n",
    "    # Suppresion des ligne dont la colonne Profil contient des nan / profil inconnu !\n",
    "    rowtodrop = RowDrop('Profil')\n",
    "    rowtodrop.fit_transform(df_fusion)\n",
    "\n",
    "    # Remplacement des Nan par des valeurs proches dans le temps selon profil et puissance inscrite\n",
    "    for profile in df_fusion['Profil'].unique():\n",
    "        for valeur_puissance in df_fusion.loc[df_fusion['Profil']==profile]['Plage de puissance souscrite'].unique():\n",
    "            mask = (df_fusion['Profil'] == profile) & (df_fusion['Plage de puissance souscrite'] ==valeur_puissance)\n",
    "            for col in df_fusion.columns:\n",
    "                if (df_fusion.loc[mask,col].isna().sum() > 0 ):\n",
    "                    if(100*df_fusion.loc[mask,col].isna().sum() / len(df_fusion.loc[mask,col]) > 80): # proportion_nan> 50%\n",
    "                        rowindex_to_drop = df_fusion.loc[mask,col].isna().index\n",
    "                        df_fusion.drop(index=rowindex_to_drop, inplace=True)\n",
    "                        #print('>80%')\n",
    "                    else :\n",
    "                        gestionvaleurmanquante= GestionValeurManquante(column_name=col, mask = mask, methode ='ffill')\n",
    "                        gestionvaleurmanquante.fit_transform(df_fusion)\n",
    "\n",
    "\n",
    "    \n",
    "    # Sauvegarde\n",
    "    \n",
    "    file_sorie = os.path.join(folder_BD_meteo_rayonnement_out, filename)\n",
    "    df_fusion.to_csv(file_sorie, index=False)\n",
    "    print('fin traitement', reg)\n",
    "\n",
    "\n",
    "for reg in Liste_region:\n",
    "    # Lecture de la base \n",
    "   nettoyage_BD(reg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auvergne-Rhône-Alpes\n",
      "fin traitement Auvergne-Rhône-Alpes\n",
      "Hauts-de-France\n",
      "fin traitement Hauts-de-France\n",
      "Provence-Alpes-Côte-d'Azur\n",
      "fin traitement Provence-Alpes-Côte-d'Azur\n",
      "Grand-Est\n",
      "fin traitement Grand-Est\n",
      "Occitanie\n",
      "fin traitement Occitanie\n",
      "Normandie\n",
      "fin traitement Normandie\n",
      "Nouvelle-Aquitaine\n",
      "fin traitement Nouvelle-Aquitaine\n",
      "Centre-Val-de-Loire\n",
      "fin traitement Centre-Val-de-Loire\n",
      "Bourgogne-Franche-Comté\n",
      "fin traitement Bourgogne-Franche-Comté\n",
      "Bretagne\n",
      "fin traitement Bretagne\n",
      "Pays-de-la-Loire\n",
      "fin traitement Pays-de-la-Loire\n",
      "Île-de-France\n",
      "fin traitement Île-de-France\n"
     ]
    }
   ],
   "source": [
    "# lecture des csv contenant les bases de données conso+meteo-rayonnement\n",
    "\n",
    "\n",
    "folder_projet_BD = r\"D:\\MesDocuments\\Formation\\DataScientist_PSL\\Projet\\BD\"\n",
    "folder_BD_meteo_rayonnement_out = os.path.join(folder_projet_BD, 'conso-inf36-meteo-rayonnement-region-propre')\n",
    "\n",
    "filename = 'departements-region.csv'\n",
    "file = os.path.join(folder_projet_BD, filename)\n",
    "df_depa_region = pd.read_csv(file)\n",
    "df_depa_region['region_name'] = df_depa_region['region_name'].apply(lambda s : s.replace(\" \", '-'))\n",
    "Liste_region = df_depa_region['region_name'].unique().tolist()\n",
    "\n",
    "for elem in ['Guadeloupe', 'Martinique', 'Guyane','La-Réunion', 'Mayotte', 'Corse']:\n",
    "    Liste_region.remove(elem)\n",
    "\n",
    "template_start_in= 'conso-inf36-meteo-rayonnement-'\n",
    "template_end_in='-' + str(2023) + '-' + str(2024) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nettoyage_heure_BD(reg):\n",
    "    filename = f\"{template_start_in}{reg}{template_end_in}\" \n",
    "    file = os.path.join(folder_BD_meteo_rayonnement_out, filename)\n",
    "    # lecture de la BD meteo de la région \n",
    "    df_fusion= pd.read_csv(file, low_memory=False)\n",
    "    df_fusion.h =df_fusion.h - 1\n",
    "    df_fusion.to_csv(file, index=False)\n",
    "    print('fin traitement', reg)\n",
    "\n",
    "\n",
    "for reg in Liste_region:\n",
    "   print(reg)\n",
    "   nettoyage_heure_BD(reg)\n",
    "   \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lecture des csv contenant les bases de données conso+meteo-rayonnement\n",
    "# Suppresion des doublons\n",
    "\n",
    "\n",
    "folder_projet_BD = r\"D:\\MesDocuments\\Formation\\DataScientist_PSL\\Projet\\BD\"\n",
    "folder_BD_meteo_rayonnement_out = os.path.join(folder_projet_BD, 'conso-inf36-meteo-rayonnement-region-propre')\n",
    "\n",
    "filename = 'departements-region.csv'\n",
    "file = os.path.join(folder_projet_BD, filename)\n",
    "df_depa_region = pd.read_csv(file)\n",
    "df_depa_region['region_name'] = df_depa_region['region_name'].apply(lambda s : s.replace(\" \", '-'))\n",
    "Liste_region = df_depa_region['region_name'].unique().tolist()\n",
    "\n",
    "for elem in ['Guadeloupe', 'Martinique', 'Guyane','La-Réunion', 'Mayotte', 'Corse']:\n",
    "    Liste_region.remove(elem)\n",
    "\n",
    "template_start_in= 'conso-inf36-meteo-rayonnement-'\n",
    "template_end_in='-' + str(2023) + '-' + str(2024) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def suppression_doublon_BD(reg):\n",
    "    filename = f\"{template_start_in}{reg}{template_end_in}\" \n",
    "    file = os.path.join(folder_BD_meteo_rayonnement_out, filename)\n",
    "    # lecture de la BD meteo de la région \n",
    "    df_fusion= pd.read_csv(file, low_memory=False)\n",
    "    df_fusion.drop_duplicates(inplace=True)\n",
    "    df_fusion.to_csv(file, index=False)\n",
    "    print('fin traitement', reg)\n",
    "\n",
    "\n",
    "for reg in Liste_region:\n",
    "    # Lecture de la base \n",
    "   suppression_doublon_BD(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Région                                          0.0\n",
       "Code région                                     0.0\n",
       "Profil                                          0.0\n",
       "Plage de puissance souscrite                    0.0\n",
       "Nb points soutirage                             0.0\n",
       "Total énergie soutirée (Wh)                     0.0\n",
       "Courbe Moyenne n°1 (Wh)                         0.0\n",
       "Indice représentativité Courbe n°1 (%)          0.0\n",
       "Courbe Moyenne n°2 (Wh)                         0.0\n",
       "Indice représentativité Courbe n°2 (%)          0.0\n",
       "Courbe Moyenne n°1 + n°2 (Wh)                   0.0\n",
       "Indice représentativité Courbe n°1 + n°2 (%)    0.0\n",
       "Jour max du mois (0/1)                          0.0\n",
       "Semaine max du mois (0/1)                       0.0\n",
       "AAAAMMJJHH                                      0.0\n",
       "T_moyenne                                       0.0\n",
       "T_STD                                           0.0\n",
       "T_min                                           0.0\n",
       "T_q25                                           0.0\n",
       "T_q50                                           0.0\n",
       "T_q75                                           0.0\n",
       "T_max                                           0.0\n",
       "FF_moyenne                                      0.0\n",
       "FF_STD                                          0.0\n",
       "FF_min                                          0.0\n",
       "FF_q25                                          0.0\n",
       "FF_q50                                          0.0\n",
       "FF_q75                                          0.0\n",
       "FF_max                                          0.0\n",
       "U_moyenne                                       0.0\n",
       "U_STD                                           0.0\n",
       "U_min                                           0.0\n",
       "U_q25                                           0.0\n",
       "U_q50                                           0.0\n",
       "U_q75                                           0.0\n",
       "U_max                                           0.0\n",
       "date                                            0.0\n",
       "year                                            0.0\n",
       "month                                           0.0\n",
       "month_n                                         0.0\n",
       "day                                             0.0\n",
       "day_n                                           0.0\n",
       "h                                               0.0\n",
       "mn                                              0.0\n",
       "s                                               0.0\n",
       "Rayonnement solaire global (W/m2)               0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "folder_projet_BD = r\"D:\\MesDocuments\\Formation\\DataScientist_PSL\\Projet\\BD\"\n",
    "folder_BD_propre= os.path.join(folder_projet_BD, 'conso-inf36-meteo-rayonnement-region-propre')\n",
    "liste_file = os.listdir(folder_BD_propre)\n",
    "reg = 0\n",
    "file = os.path.join(folder_BD_propre,liste_file[reg]) #'conso-inf36-Auvergne-Rhône-Alpes-2023-2024.csv') #\n",
    "df = pd.read_csv(file, low_memory=False)\n",
    "\n",
    "# isna\n",
    "100*df.isna().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
