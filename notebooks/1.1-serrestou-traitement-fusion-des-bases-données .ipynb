{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Auteur: Y.s ###########\n",
    "############ Fev 2024 ##############\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import gzip\n",
    "from datetime import datetime\n",
    "\n",
    "# spécification des chamins locaux\n",
    "folder_projet_BD = r\"D:\\MesDocuments\\Formation\\DataScientist_PSL\\Projet\\BD\"\n",
    "folder_BD_meteo = os.path.join(folder_projet_BD, 'Meteo\\CSV')\n",
    "folder_BD_meteo_region = os.path.join(folder_projet_BD, 'Meteo/region')\n",
    "folder_BD_conso = os.path.join(folder_projet_BD, 'conso-inf36-region')\n",
    "folder_BD_meteo_rayonnement = os.path.join(folder_projet_BD, 'Meteo/rayonnement')\n",
    "\n",
    "folder_BD_meteo_rayonnement_out = os.path.join(folder_projet_BD, 'Meteo/region_rayonnement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie nous traitons les données du rayonnement solaire. Les données sont tri-horaire (toutes les trois heures) et par région. \n",
    "Les autres données sont données par pas d'une heure, et la consommation par une pas d'une demi-heure.\n",
    "Pour avoir le même pas nous dupliquons les mesure pour les heures proches :  mesures de 01h00 sera dupliqué pour (00,01,02), celle de 04h00 pour (03,04,05),...celle de 22h00 sera dupliqué pour (21,22,23). \n",
    "Ce traitement suppose que le  rayonnement est assez constant une heure avant et une heure après l'heure de mesure. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def traitement_rayonnement(folder_BD_meteo_rayonnement_in, folder_BD_meteo_rayonnement_out):\n",
    "  \"\"\"\n",
    "    Traiter  les fichiers rayonnement-solaire-vitesse-vent-tri-horaires-regionaux\n",
    "  \"\"\"\n",
    "  for f in os.listdir(folder_BD_meteo_rayonnement_in):\n",
    "    file = os.path.join(folder_BD_meteo_rayonnement_in, f)\n",
    "    if os.path.isfile(file):\n",
    "      # Ouverture et lecture du fichier csv\n",
    "      df_rayonnement_region = pd.read_csv(file, sep=';')\n",
    "      \n",
    "      # Extraction et ajout des champs année, mois, jours, heure, on fait cette extraction uniquement lors de la première lecture \n",
    "   \n",
    "      df_info = pd.to_datetime(df_rayonnement_region['Date'].astype(str), \n",
    "                                 format =\"%Y%m%dT%H\").apply(lambda t: pd.Series({'date': t.date(),\n",
    "                                                                     \n",
    "                                                                                'year': t.strftime(\"%Y\"),\n",
    "                                                                                'month': t.strftime(\"%m\"),\n",
    "                                                                                'month_n': t.strftime(\"%B\"),\n",
    "                                                                                'day': t.strftime(\"%d\"),\n",
    "                                                                                'day_n': t.strftime(\"%A\"),\n",
    "                                                                                'h': t.hour,\n",
    "                                                                                #'mn': t.minute, \n",
    "                                                                                's': t.second,\n",
    "                                                                                }))\n",
    "    \n",
    "    # On ajoute des colonnes horaires %year, %month...\n",
    "      df_rayonnement_region[df_info.columns] = df_info\n",
    "    # On duplique les plage tri-horaire trois fois on obtient pour les heures ((2,2,2), (5,5,5),..., (23,23,23) )\n",
    "      df_rayonnement_region = pd.concat([df_rayonnement_region]*3)\n",
    "    # On réordonne\n",
    "      df_rayonnement_region.sort_values(['year', 'month', 'day', 'h'], ascending=[True, True,True,True], inplace=True)\n",
    "    # On reindexe\n",
    "      df_rayonnement_region.reset_index(inplace=True) \n",
    "    # on modifie les heures   (2,2,2) --> (2,3,4); (5,5,5) --> (5,6,7)....\n",
    "      df_rayonnement_region['h'] = (df_rayonnement_region['h'] + (df_rayonnement_region.index % 3) - 1) % 24\n",
    "    # On réordonne\n",
    "      df_rayonnement_region.sort_values(['year', 'month', 'day', 'h'], ascending=[True, True,True,True], inplace=True)\n",
    "    # Création d'un champ AAAAMMJJHH identique aux autres df (météo et consommation)\n",
    "      df_rayonnement_region['AAAAMMJJHH'] = df_rayonnement_region['year'] + df_rayonnement_region['month'] + df_rayonnement_region['day'] +(df_rayonnement_region['h'].astype(str))*(df_rayonnement_region['h'] >= 12) + ('0'  + df_rayonnement_region['h'].astype(str))*(df_rayonnement_region['h'] < 12)\n",
    "    # Sauvegarde\n",
    "    \n",
    "      df_to_save =  df_rayonnement_region[['AAAAMMJJHH','Rayonnement solaire global (W/m2)' ]]\n",
    "      filename = \"Rayonnement_solaire_global_\"\t+ f\"{df_rayonnement_region['Région'].unique()[0]}\" +'.csv'\n",
    "      file_sorie = os.path.join(folder_BD_meteo_rayonnement_out, filename)\n",
    "      df_to_save.to_csv(file_sorie, index=False)\n",
    "\n",
    "\n",
    "traitement_rayonnement(folder_BD_meteo_rayonnement, folder_BD_meteo_rayonnement_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggrégation des données météo par région :\n",
    "# ======================================================================================\n",
    "# Nous gardons que les champs suivantes :\n",
    "# NUM_POSTE   \t numéro Météo-France du poste sur 8 chiffres ==> permet d'identier \n",
    "# NOM_USUEL   \t nom usuel du poste\n",
    "# LAT         \t latitude, négative au sud (en degrés et millionièmes de degré)\n",
    "# LON         \t longitude, négative à l’ouest de GREENWICH (en degrés et millionièmes de degré)\n",
    "# ALTI        \t altitude du pied de l'abri ou du pluviomètre si pas d'abri (en m)\n",
    "# AAAAMMJJHH  \t date de la mesure (année mois jour heure)\n",
    "# FF          \t force du vent moyenné sur 10 mn, mesurée à 10 m (en m/s et 1/10)\n",
    "# T           \t température sous abri instantanée (en °C et 1/10)\n",
    "# U           \t humidité relative (en %)\n",
    "# ======================================================================================\n",
    "# Pour \n",
    "    # DIF         \t  rayonnement diffus horaire en heure UTC (en J/cm2) \n",
    "    # DIR         \t  rayonnement direct  horaire en heure UTC (en J/cm2)\n",
    "# Vu qu'ils contiennent beacoup de données manquantes, nous utilsons une autre base avec le rayonnment global à l'échelle d'une région \n",
    "\n",
    "# Dans une région, il y plusieurs postes : \n",
    "# on remplace les mesurs de tous ces postes par les moments statistiques\n",
    "    # d'ordre 1  : moyenne, \n",
    "    # d'ordre 2 : écrat-type, \n",
    "    # d'ordre 3 : asymétrie (skewness), \n",
    "    # d'ordre 4 : l'applatissement (kurtosis )\n",
    "# Fonction pour calculer les moments \n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "# Les fonctions à appliquer \n",
    "# 25th Percentile\n",
    "def q25(x):\n",
    "    return x.quantile(0.25)\n",
    "# 50th Percentile\n",
    "def q50(x):\n",
    "    return x.quantile(0.5)\n",
    "\n",
    "# 90th Percentile\n",
    "def q75(x):\n",
    "    return x.quantile(0.75)\n",
    "# Suite à un problème avec skew et kurtosis (trop de valeure nan)\n",
    "#aggregation = {\"T\":[(\"moyenne\",'mean'), ('STD', 'std'), ('skew', lambda x : skew(x)),('kurtosis', lambda x : kurtosis(x)) ],\n",
    "#               \"FF\":[(\"moyenne\",'mean'), ('STD', 'std'), ('skew', lambda x : skew(x)),('kurtosis', lambda x : kurtosis(x)) ],\n",
    "#               \"U\":[(\"moyenne\",'mean'), ('STD', 'std'), ('skew', lambda x : skew(x)),('kurtosis', lambda x : kurtosis(x)) ],\n",
    "#               }\n",
    "# Je remplace par les quartiles\n",
    "aggregation = {\"T\":[(\"moyenne\",'mean'), ('STD', 'std'), ('min' , 'min'), ('q25', lambda x : q25(x)),('q50', lambda x : q50(x)), ('q75', lambda x : q75(x)), ('max', 'max'),('skew', lambda x : skew(x)),('kurtosis', lambda x : kurtosis(x))],\n",
    "               \"FF\":[(\"moyenne\",'mean'), ('STD', 'std'),('min' , 'min'), ('q25', lambda x : q25(x)),('q50', lambda x : q50(x)), ('q75', lambda x : q75(x)),('max', 'max'),('skew', lambda x : skew(x)),('kurtosis', lambda x : kurtosis(x)) ],\n",
    "               \"U\":[(\"moyenne\",'mean'), ('STD', 'std'),('min' , 'min'), ('q25', lambda x : q25(x)),('q50', lambda x : q50(x)), ('q75', lambda x : q75(x)),('max', 'max'),('skew', lambda x : skew(x)),('kurtosis', lambda x : kurtosis(x)) ],\n",
    "               }\n",
    "# Téléchargement de la BD avec région et département\n",
    "filename = 'departements-region.csv'\n",
    "file = os.path.join(folder_BD_meteo, filename)\n",
    "df_depa_region = pd.read_csv(file)\n",
    "# JE remplace les espace par un '-' dans les noms des régions\n",
    "df_depa_region['region_name'] = df_depa_region['region_name'].apply(lambda s : s.replace(\" \", '-'))\n",
    "\n",
    "Liste_region = df_depa_region['region_name'].unique().tolist()\n",
    "\n",
    "# df_depa_region['region_name'].unique() # pour vérifer\n",
    "# Je supprime les régions  ['Guadeloupe', 'Martinique', 'Guyane','La-Réunion', 'Mayotte', 'Corse']\n",
    "\n",
    "for elem in ['Guadeloupe', 'Martinique', 'Guyane','La-Réunion', 'Mayotte', 'Corse']:\n",
    "    Liste_region.remove(elem)\n",
    "\n",
    "# Construction d'un dictionnaire de clés région et de valeurs la liste des nuémros de départements de chaque région \n",
    "dictionnaire__departement_region = {}\n",
    "\n",
    "for reg in Liste_region:\n",
    "    dictionnaire__departement_region[reg] = df_depa_region.loc[df_depa_region['region_name']==reg, 'num_dep'].tolist()\n",
    "\n",
    "# Construction de la nouvelle base avec les caractéristiques décrites précédement\n",
    "# Un fichir csv par région pour 2023-2024\n",
    "template_start= 'H_' # début du nom du fichier\n",
    "template_end_2020='_previous-' + str(2020) + '-' + str(2023) + '.csv'\n",
    "template_end_2024='_latest-' + str(2024) + '-' + str(2025) + '.csv'\n",
    "template_end_reg='-' + str(2023) + '-' + str(2024) + '.csv'\n",
    "\n",
    "# Les colonnes à garder\n",
    "columns_to_keep = ['AAAAMMJJHH','T', 'FF', 'U']\n",
    "for reg, list_dep in dictionnaire__departement_region.items():\n",
    "    print(\"... Nous traitons la région\", reg)\n",
    "    premier_departement = True\n",
    "    for dep in list_dep:\n",
    "        # #Lecture de la dataframe avec des données 2020-2023\n",
    "        filename  = f\"{template_start}{dep}{template_end_2020}\" \n",
    "        file = os.path.join(folder_BD_meteo, filename)\n",
    "        \n",
    "        df =  pd.read_csv(file, sep=';')\n",
    "        # suppression des colonnes\n",
    "        df_2023_dep =df[columns_to_keep]\n",
    "\n",
    "        # On ne garde que les lignes de 2023\n",
    "        df_2023_dep = df_2023_dep.loc[df_2023_dep['AAAAMMJJHH']>=2023010100]\n",
    "\n",
    "    # Lecture des fichiers 2024-2025\n",
    "        filename  = f\"{template_start}{dep}{template_end_2024}\" \n",
    "        file = os.path.join(folder_BD_meteo, filename)\n",
    "        df_2024_dep =  pd.read_csv(file, sep=';')\n",
    "        # chargement \n",
    "        df =  pd.read_csv(file, sep=';')\n",
    "        # suppression des colonnes\n",
    "        df_2024_dep =df[columns_to_keep]\n",
    "\n",
    "        # On ne garde que les lignes de 2024\n",
    "        df_2024_dep = df_2024_dep.loc[df_2024_dep['AAAAMMJJHH']<2025010100]\n",
    "\n",
    "      \n",
    "\n",
    "        # Union des deux df 2023 et 2024  avec la df de la région\n",
    "        if premier_departement == True:\n",
    "            df_2023_2024 = pd.concat([df_2023_dep, df_2024_dep], ignore_index=True)\n",
    "            premier_departement = False \n",
    "        else:\n",
    "            df_2023_2024 = pd.concat([df_2023_2024,df_2023_dep, df_2024_dep], ignore_index=True)\n",
    "    # Maintenant on a un df de la région avec les champs souhaités\n",
    "    # On applique les stats \n",
    "    df_stat_2023_2024 = df_2023_2024.groupby('AAAAMMJJHH').agg(aggregation)\n",
    "    df_stat_2023_2024.columns = df_stat_2023_2024.columns.map('_'.join)\n",
    "    df_stat_2023_2024.reset_index(inplace=True) # reindexation\n",
    "\n",
    "    # Extraction et ajout des champs année, mois, jours, heure\n",
    "    df_info = pd.to_datetime(df_stat_2023_2024['AAAAMMJJHH'].astype(str), \n",
    "                                 format =\"%Y%m%d%H\").apply(lambda t: pd.Series({'date': t.date(),\n",
    "                                                                                'year': t.year,\n",
    "                                                                                'month': t.month,\n",
    "                                                                                'month_n': t.strftime(\"%B\"),\n",
    "                                                                                'day': t.day,\n",
    "                                                                                'day_n': t.strftime(\"%A\"),\n",
    "                                                                                'h': t.hour ,\n",
    "                                                                                'mn': t.minute,\n",
    "                                                                                's': t.second,\n",
    "                                                                                }))\n",
    "    df_stat_2023_2024[df_info.columns] = df_info\n",
    "\n",
    "    # On sauvegarde dans un CSV : nom   = H_region-2023-2024.csv\" \n",
    "    filename = f\"{template_start}{reg}{template_end_reg}\" \n",
    "    file = os.path.join(folder_BD_meteo_region, filename)\n",
    "    df_stat_2023_2024.to_csv(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement de la BD avec région et département\n",
    "filename = 'departements-region.csv'\n",
    "file = os.path.join(folder_BD_meteo, filename)\n",
    "df_depa_region = pd.read_csv(file)\n",
    "# JE remplace les espace par un '-' dans les noms des régions\n",
    "df_depa_region['region_name'] = df_depa_region['region_name'].apply(lambda s : s.replace(\" \", '-'))\n",
    "\n",
    "Liste_region = df_depa_region['region_name'].unique().tolist()\n",
    "\n",
    "# df_depa_region['region_name'].unique() # pour vérifer\n",
    "# Je supprime les régions  ['Guadeloupe', 'Martinique', 'Guyane','La-Réunion', 'Mayotte', 'Corse']\n",
    "\n",
    "for elem in ['Guadeloupe', 'Martinique', 'Guyane','La-Réunion', 'Mayotte', 'Corse']:\n",
    "    Liste_region.remove(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Nous traitons la région Auvergne-Rhône-Alpes\n",
      "... Extraction Auvergne-Rhône-Alpes\n",
      "... Fusion Auvergne-Rhône-Alpes\n",
      "... Enregistrement dans un csv Auvergne-Rhône-Alpes\n",
      "... Nous traitons la région Hauts-de-France\n",
      "... Extraction Hauts-de-France\n",
      "... Fusion Hauts-de-France\n",
      "... Enregistrement dans un csv Hauts-de-France\n",
      "... Nous traitons la région Provence-Alpes-Côte-d'Azur\n",
      "... Extraction Provence-Alpes-Côte-d'Azur\n",
      "... Fusion Provence-Alpes-Côte-d'Azur\n",
      "... Enregistrement dans un csv Provence-Alpes-Côte-d'Azur\n",
      "... Nous traitons la région Grand-Est\n",
      "... Extraction Grand-Est\n",
      "... Fusion Grand-Est\n",
      "... Enregistrement dans un csv Grand-Est\n",
      "... Nous traitons la région Occitanie\n",
      "... Extraction Occitanie\n",
      "... Fusion Occitanie\n",
      "... Enregistrement dans un csv Occitanie\n",
      "... Nous traitons la région Normandie\n",
      "... Extraction Normandie\n",
      "... Fusion Normandie\n",
      "... Enregistrement dans un csv Normandie\n",
      "... Nous traitons la région Nouvelle-Aquitaine\n",
      "... Extraction Nouvelle-Aquitaine\n",
      "... Fusion Nouvelle-Aquitaine\n",
      "... Enregistrement dans un csv Nouvelle-Aquitaine\n",
      "... Nous traitons la région Centre-Val-de-Loire\n",
      "... Extraction Centre-Val-de-Loire\n",
      "... Fusion Centre-Val-de-Loire\n",
      "... Enregistrement dans un csv Centre-Val-de-Loire\n",
      "... Nous traitons la région Bourgogne-Franche-Comté\n",
      "... Extraction Bourgogne-Franche-Comté\n",
      "... Fusion Bourgogne-Franche-Comté\n",
      "... Enregistrement dans un csv Bourgogne-Franche-Comté\n",
      "... Nous traitons la région Bretagne\n",
      "... Extraction Bretagne\n",
      "... Fusion Bretagne\n",
      "... Enregistrement dans un csv Bretagne\n",
      "... Nous traitons la région Pays-de-la-Loire\n",
      "... Extraction Pays-de-la-Loire\n",
      "... Fusion Pays-de-la-Loire\n",
      "... Enregistrement dans un csv Pays-de-la-Loire\n",
      "... Nous traitons la région Île-de-France\n",
      "... Extraction Île-de-France\n",
      "... Fusion Île-de-France\n",
      "... Enregistrement dans un csv Île-de-France\n"
     ]
    }
   ],
   "source": [
    "# Concaténation des deux bases de données conso + météo \n",
    "# Pour la consommation \n",
    "template_start_in_meteo= 'H_' # début du nom du fichier meteo \n",
    "template_start_in_conso = 'conso-inf36-' # début du nom du fichier conso  \n",
    "template_end_in='-' + str(2023) + '-' + str(2024) + '.csv'\n",
    "\n",
    "# Pour le fichier csv d'unification des BD\n",
    "template_start_out= 'conso-inf36-meteo-' # début du nom du fichier conso-meteo\n",
    "template_end_out='-' + str(2023) + '-' + str(2024) + '.csv'\n",
    "\n",
    "# Gestion des repertoires \n",
    "folder_projet_BD = r\"D:\\MesDocuments\\Formation\\DataScientist_PSL\\Projet\\BD\"\n",
    "folder_BD_meteo = os.path.join(folder_projet_BD, 'Meteo\\CSV')\n",
    "folder_BD_meteo_region = os.path.join(folder_projet_BD, 'Meteo/region')\n",
    "folder_BD_conso_region = os.path.join(folder_projet_BD, 'conso-inf36-region')\n",
    "folder_BD_conso_meteo = os.path.join(folder_projet_BD, 'conso-inf36-meteo-region')\n",
    "\n",
    "if not os.path.isdir(folder_BD_conso_meteo):\n",
    "    os.mkdir(folder_BD_conso_meteo)\n",
    "for reg in Liste_region:\n",
    "#def data_conso_meteo_fusion (reg):\n",
    "    print(\"... Nous traitons la région\", reg)\n",
    "    # Lecture de la base meteo de la région \n",
    "    filename = f\"{template_start_in_meteo}{reg}{template_end_in}\" \n",
    "    file = os.path.join(folder_BD_meteo_region, filename)\n",
    "    # lecture de la BD meteo de la région \n",
    "    df_meteo_region = pd.read_csv(file)\n",
    "    df_meteo_region.drop(columns = ['Unnamed: 0'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Lecture de la base conso de la région \n",
    "    filename = f\"{template_start_in_conso}{reg}{template_end_in}\" \n",
    "    file = os.path.join(folder_BD_conso_region, filename)\n",
    "    # lecture de la BD conso de la région \n",
    "    df_conso_region = pd.read_csv(file, sep = ';')\n",
    "  \n",
    "    print(\"... Extraction\", reg)\n",
    "# # Extraction et ajout des champs année, mois, jours, heure pour la base conso\n",
    "    df_info = pd.to_datetime(df_conso_region['Horodate'],utc=True).apply(lambda t: pd.Series({\n",
    "        #'date': t.date(),\n",
    "        'year': t.year,\n",
    "        'month': t.month,\n",
    "        #'month_n': t.strftime(\"%B\"),\n",
    "        'day': t.day,\n",
    "        #'day_n': t.strftime(\"%A\"),\n",
    "        'h': t.hour,\n",
    "        'mn': t.minute,\n",
    "        #'s': t.second,\n",
    "    }))\n",
    "\n",
    "    df_conso_region[df_info.columns] = df_info\n",
    "    # Ajout d'une colonne 'AAAAMMJJHH' qui va nous servir comme colonne commune pour unifier (merge) les deux bases\n",
    "    df_conso_region['AAAAMMJJHH'] = df_info.h + df_info.day*100+ df_info.month*10000 + df_info.year*1000000\n",
    "\n",
    "    # Suppression des colonnes pour ne pas avoir de doublons\n",
    "    df_conso_region.drop(columns=['year', 'month', 'day', 'h',  'Horodate'], inplace=True)\n",
    "   \n",
    "\n",
    "    print(\"... Fusion\", reg)\n",
    "    # Fusion des deux bases\n",
    "    df_fusion = df_conso_region.merge(right = df_meteo_region, on =\"AAAAMMJJHH\", how = 'right')\n",
    "    print(\"... Enregistrement dans un csv\", reg)\n",
    "    # Enregistrement dans des csv\n",
    "    filename = f\"{template_start_out}{reg}{template_end_out}\" \n",
    "    file = os.path.join(folder_BD_conso_meteo, filename)\n",
    "    # lecture de la BD meteo de la région \n",
    "    df_fusion.to_csv(file, index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Nous traitons la région Auvergne-Rhône-Alpes\n",
      "... Fusion Auvergne-Rhône-Alpes\n",
      "... Enregistrement dans un csv Auvergne-Rhône-Alpes\n",
      "... Nous traitons la région Hauts-de-France\n",
      "... Fusion Hauts-de-France\n",
      "... Enregistrement dans un csv Hauts-de-France\n",
      "... Nous traitons la région Provence-Alpes-Côte-d'Azur\n",
      "... Fusion Provence-Alpes-Côte-d'Azur\n",
      "... Enregistrement dans un csv Provence-Alpes-Côte-d'Azur\n",
      "... Nous traitons la région Grand-Est\n",
      "... Fusion Grand-Est\n",
      "... Enregistrement dans un csv Grand-Est\n",
      "... Nous traitons la région Occitanie\n",
      "... Fusion Occitanie\n",
      "... Enregistrement dans un csv Occitanie\n",
      "... Nous traitons la région Normandie\n",
      "... Fusion Normandie\n",
      "... Enregistrement dans un csv Normandie\n",
      "... Nous traitons la région Nouvelle-Aquitaine\n",
      "... Fusion Nouvelle-Aquitaine\n",
      "... Enregistrement dans un csv Nouvelle-Aquitaine\n",
      "... Nous traitons la région Centre-Val-de-Loire\n",
      "... Fusion Centre-Val-de-Loire\n",
      "... Enregistrement dans un csv Centre-Val-de-Loire\n",
      "... Nous traitons la région Bourgogne-Franche-Comté\n",
      "... Fusion Bourgogne-Franche-Comté\n",
      "... Enregistrement dans un csv Bourgogne-Franche-Comté\n",
      "... Nous traitons la région Bretagne\n",
      "... Fusion Bretagne\n",
      "... Enregistrement dans un csv Bretagne\n",
      "... Nous traitons la région Pays-de-la-Loire\n",
      "... Fusion Pays-de-la-Loire\n",
      "... Enregistrement dans un csv Pays-de-la-Loire\n",
      "... Nous traitons la région Île-de-France\n",
      "... Fusion Île-de-France\n",
      "... Enregistrement dans un csv Île-de-France\n"
     ]
    }
   ],
   "source": [
    "# Concaténation des deux bases de données conso-météo + rayonnement \n",
    "# Pour la consommation \n",
    "template_start_in_meteo= 'Rayonnement_solaire_global_' # début du nom du fichier meteo \n",
    "template_start_in_conso = 'conso-inf36-meteo-' # début du nom du fichier conso  \n",
    "template_end_in='-' + str(2023) + '-' + str(2024) + '.csv'\n",
    "\n",
    "\n",
    "\n",
    "# Pour le fichier csv d'unification des BD\n",
    "template_start_out= 'conso-inf36-meteo-rayonnement-' # début du nom du fichier conso-meteo\n",
    "template_end_out='-' + str(2023) + '-' + str(2024) + '.csv'\n",
    "\n",
    "# Gestion des repertoires \n",
    "folder_projet_BD = r\"D:\\MesDocuments\\Formation\\DataScientist_PSL\\Projet\\BD\"\n",
    "folder_BD_conso_meteo = os.path.join(folder_projet_BD, 'conso-inf36-meteo-region')\n",
    "folder_BD_rayonnement_region = os.path.join(folder_projet_BD, 'Meteo/region_rayonnement')\n",
    "folder_BD_meteo_rayonnement_region = os.path.join(folder_projet_BD, 'conso-inf36-meteo-rayonnement-region')\n",
    "\n",
    "for reg in Liste_region:\n",
    "#def data_conso_meteo_fusion (reg):\n",
    "    print(\"... Nous traitons la région\", reg)\n",
    "    # Lecture de la base rayonnement de la région \n",
    "    filename = f\"{template_start_in_meteo}{reg}{'.csv'}\" \n",
    "    file = os.path.join(folder_BD_rayonnement_region, filename)\n",
    "    # lecture de la BD meteo de la région \n",
    "    df_meteo_region = pd.read_csv(file)\n",
    "    \n",
    "\n",
    "    # Lecture de la base meteo de la région \n",
    "    filename = f\"{template_start_in_conso}{reg}{template_end_in}\" \n",
    "    file = os.path.join(folder_BD_conso_meteo, filename)\n",
    "    # lecture de la BD meteo de la région \n",
    "    df_conso_region = pd.read_csv(file)\n",
    "\n",
    "\n",
    "    print(\"... Fusion\", reg)\n",
    "    # Fusion des deux bases\n",
    "    df_fusion = df_conso_region.merge(right = df_meteo_region, on =\"AAAAMMJJHH\", how = 'right')\n",
    "    print(\"... Enregistrement dans un csv\", reg)\n",
    "    # Enregistrement dans des csv\n",
    "    filename = f\"{template_start_out}{reg}{template_end_out}\" \n",
    "    file = os.path.join(folder_BD_meteo_rayonnement_region, filename)\n",
    "    # lecture de la BD meteo de la région \n",
    "    df_fusion.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
